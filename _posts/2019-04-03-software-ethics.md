---
layout: post
title: Software Ethics
author: Guy Burroughes
date: May 2019
abstract: This is a brief article I started working on before the Pandemic, then life got away from me. I haven't rethought the position since, but I do believe the major concept still holds. Special thanks to Prof. Alan Winfield for discussing this topic with me. I thought about getting published in a peer reviewed journal, but I would have to wait for the "Old man shouting at cloud" special issue.
---

# An urgent need 

{:.BodyText .Justified}
Future elections and democracies will be irrevocably damaged by Deepfakes.  At the end of 2017, a Reddit user going by the name Deepfakes released a machine learning-based software package capable of faking footage of another person with no technical expertise required. Non-consensual pornography of celebrities was an immediate consequence of the public availability of this software [1] [2]. Whilst this is doubtlessly of great personal distress to the people affected, even more worrying for society is the effect the availability of this technology will have on the public’s relationship with the truth, with examples of Deepfakes being used to defame politicians appearing on major news channels, such as fake footage of US Speaker of the House Nancy Pelosi appearing on Fox news [3]. In the 2020 US presidential elections, without urgent action, deep-fakes will wash across social media further eroding the public’s ability to identify “fake news”. 

Image result for deepfake politics 

Figure 1: Real-time impersonation of political leaders. 

{:.BodyText .Justified}
2019 saw the release by Google of a similar advancement, this time allowing for the accurate reproduction of a person’s voice from a 5-second recording [4]. This technology will also have chilling effects, enabling malicious actors to accurately reproduce any voice. For example In 2019, a U.K.-based energy firm’s CEO was scammed over the phone when he was ordered to transfer €220,000 into a Hungarian bank account by an individual who used audio Deepfake technology to impersonate the voice of the firm's parent company's chief executive [5]. Google’s publication will make this type of fraud easier.  

{:.BodyText .Justified}
Without immediate action, machine learning research will produce even more troubling results and lead to public backlash towards the technology and community. But Machine learning is highly technical field which is hard to define and changes at a rate not compatible with the reasoned debate of legislation. Moreover, the discussion of ML research ethics often gets distracted by the concept of artificial general intelligence and physical robots such as the “Terminator”, but significant damage will be caused by much more innocuous algorithms which cannot be seen and which can be run on any computer. Thus, lawmakers and governments are not equipped to control this rapidly changing field without stifling developments through broad over-reaching legislation. And the complexities of regulating a specific use of a general-purpose machine is a field of study in itself.  

{:.BodyText .Justified}
While these issues are concerning, research and professional ethics is a well-understood problem in other fields. For example, in biotechnology research the public good is weighed against the value of research by ethics committees. It is questionable whether an ethics committee would be convinced of the benefits of the technology versus the damage of research such as Google’s audio transfer technology.  

{:.BodyText .Justified}
Thus, to avoid further damage the Machine-Learning research community must organise to self-regulate developments. Before any research is carried out it must be subject to an independent review by an ethics committee. Funding agencies and publication bodies should demand proof of ethics reviews and the machine learning community must be formalised as a profession with governing bodies, with those professions becoming integral to all parts of the community including education. 

 

 

# Historical Context 

{:.BodyText .Justified}
Since the enlightenment, research has been motivated by a positive assurance that its results will benefit of humankind. The field of Research Ethics address some of the reasons why distrust in research could develop in parallel to this optimistic belief in future progress. Such distrust arose in the wake of abuse directed at individuals and fear of destructive consequences for society and life. In these conflicts, a recognition arose of how these internal scientific norms (as well as the professional ethics of the researchers) were insufficient to protect individuals against abuse and prevent destructive consequences. The Second World War is considered the most important landmark in research ethics, with the scientific and medical experiments conducted on prisoners of war in the concentration camps . Altogether 23 doctors were brought to justice in Nuremberg in 1947 for having conducted medical research on people in the concentration camps. As a direct result of the trial, the Nuremberg Code was established in 1948, stating that "The voluntary consent of the human subject is absolutely essential," making it clear that subjects must give consent, and that the benefits of research must outweigh the risks.  Although it did not carry the force of law, the Nuremberg Code was the first international document which advocated voluntary participation and informed consent. Another key event in research ethics was the Manhattan Project, a large-scale research project to produce atomic bombs, which marked a landmark where theoretical research would rapidly developed to  a world destroying threat. 

{:.BodyText .Justified}
It is interesting to note some of the differences between these two research areas. In the medical field, there was very little willingness among the researchers to undertake self-criticism or reckoning [6]. In contrast,  in the natural sciences, the researchers themselves alerted the world to the possibilities for mass destruction resulting from the use of nuclear weapons [7] [8]. There were even attempts to subvert development with Einstein withholding publications for decades to avoid the technology falling into the wrong hands [9]. Whereas even after initial ethical reform efforts within the medical field in the 40’s and 50’s, ethical issues persisted. This is witnessed through continued ethical issues in the medical community illustrated by the Tuskegee experiments and thalidomide’s catastrophic widespread distribution.  

{:.BodyText .Justified}
Building on the Nuremberg code, in 1953 and 1962 the Medical Research Council published statements on the conduct of research. The Nuremberg principles were adopted and developed by the World Medical Association in the Declaration of Helsinki 1964 (substantially revised in 2000), which contains the fundamental principle that, whilst scientific progress is an important public good, “...considerations related to the well-being of the human subject should take precedence over the interests of science and society”. 

{:.BodyText .Justified}
In 1966 the first research ethics committees were set up in the United Kingdom, but it was not until 1991 that Department of Health guidelines on Local Research Ethics Committees was finally published, and followed in 1997 by the creation of Multi-Centre Research Ethics Committees. Public scandals, such as an inquiry into allegations of misconduct concerning a research study in North Staffordshire [10], served to highlight a number of procedural defects which led to the introduction of the Research Governance Framework for Health and Social Care [11] and the establishment of the Central Office for Research Ethics Committees. 

{:.BodyText .Justified}
This short history lesson serves to demonstrate a resistance to medical ethics which now appears to be integral and foundational to the medical field. This resistance to regulation is also present in the ML field.  

# Arguments against self-regulation 

{:.BodyText .Justified}
The main argument against self-regulation which has been informally discussed at conferences is its believed infeasibility. However, many other fields have managed the transition to “profession”. What follows is an exploration into the arguments that are used to demonstrate infeasibility, with this setting the relational context to other fields will be established, and details of the proposed profession will be expanded upon.  

{:.BodyText .Justified}
One of the largest distinctions in the advances made in the field of ML versus other fields is their digital nature. Deepfakes is dangerous because it is easy to use and can be “copied and pasted”. Essentially, there is no barrier to entry to the technology; it has been possible to fake videos to some degree for years, but it provided a skill and cost barrier that Deepfakes removes. However, this only strengthens the argument for limiting certain potentially dangerous research. Moreover, this is not a unique issue for there are other fields, namely bio-engineering, where dangerous pathogens could be engineered and could be reproduced with relative ease if malicious actors obtained them [12]. Thus, bio-engineering research is heavily regulated and monitored by ethics committees. In the medical field, ethics committees exist to safeguard the rights, safety, dignity and well-being of research participants; ensuring equity for research participants such that the research will likely benefit those putting themselves at risk – it is not ethical to test a drug in poorer countries which will only ever benefit developed countries.  An NHS ethics committee consists of 15 members, with a third being lay-people with no field expertise [13].   

{:.BodyText .Justified}
An additional argument comes from the anonymous nature of the internet, allowing for malicious ML research or its products to be easily and anonymously propagated.  This issue is not unique to ML research, with examples of dangerous chemistry methods for making dangerous substances (e.g. explosives) being limited in publication [14]. It is worth noting that in established publications within the Medical field, publishers and editors will host quarterly ethics reviews. These reviews are to ensure the ethics of publications and have recently been strengthened in response to the MMR vaccination scandal in the Lancet [15] and a reproducibility crisis [16]. It is worth noting at this point that ML is also facing a reproducibility crisis [17], which is exacerbated through the use of Arxiv as the primary publishing platform removing the low bar of peer-review, with 344 ML publications to the Arxiv between the 2nd and 4th of December 2019, for example; further illustrated in Figure 2. 

Image result for arxiv machine learning 

Figure 2: Machine Learning Arxiv papers per year vs Moore’s Law 

{:.BodyText .Justified}
Consequently, there is a follow-up argument that regulation will only limit good actors.  This is a standard issue for any field considering regulation. Medical research is easily regulatable, and there are numerous highly profitable research fields that have been limited for ethical reasons (e.g. cloning). Moreover, even in countries that have a low rank of ethical indexing act swiftly to enforce medical research ethics, for example China’s CRISPR CAS9 twin incident in which the researchers are still under investigation [18]. As this issue is clearly deemed acceptable by other fields, it’s would be hard to justify why ML research is different. As a short addendum argument, it often stated that research should be carried out by good actors in order to understand and limit the damage made possible by malicious actors. This argument is also deemed insufficient by other fields, with medical research not encouraging the development of Smallpox 2.0 “just-in-case”.  

{:.BodyText .Justified}
Any ethically driven profession manages to (self) regulate through requiring actors to become affiliated to a centralised professional body (there may be more than one available). This can be achieved through hiring organisations requiring affiliation with a professional body or legislation requiring affiliation with a professional body. Once affiliated actors are subject to the ethical regulation of the professional body, those members may be subject to investigation and expulsion on ethics violations. An additional benefit is the increased bargaining power the community gains from the centralised coordination. As part of the RAS 2020 report [19] a leadership council for the Robotics and autonomous system research field was deemed necessary. Research Councils UK advocated a complementary approach, namely establishing a RAS national flagship institute “with the dual purpose of accelerating emerging technologies to commercialisation and inspiring new disruptive academic research with the potential to open up new markets” [20]. A professional body would clearly fulfil this purpose whilst enforcing ethical guidelines and standards.  

{:.BodyText .Justified}
An interesting method proposed for limiting unethical research in the biotechnology field is through the use of patents. Thus, as a suggestion one could obtain a patent on the use of Deepfake-like technology applied for unethical purposes or the products thereof. This would allow the owner of the patent to sue websites, newspapers or producers that host or create unethical Deepfake materials, performing an ethical service to the world whilst making a profit from bad actors 

# Self-Regulation of ML 

{:.BodyText .Justified}
It is proposed that the field of Machine Learning self-regulates through mandatory affiliation to a professional body inorder to practice. This professional body would require members to follow ethical guidelines and standards. Ethics reviews would need to be convened prior to any research, and work with significant consequences would require the convening of an ethics committee. The ethics committee would consist of neutral experts and lay-people determining review work to maximise the potential value to society from the research. The professional body would support this process, minimising the impact and cost of this process on individual researchers.  

{:.BodyText .Justified}
Additionally, the professional body would also provide unionisation of the profession, a method for collective bargaining; and so improve working conditions for a foundling occupation. Moreover, the profession would establish training presence; defining a baseline of training or experience before one can be considered a professional, ensuring the profession maintains its high standing in society. 

{:.BodyText .Justified}
A set of leading Councils would have to be appointed to determine the ethical guidelines. Ethical guidelines or a Code of Ethics and guidelines would not only focus on social issues but also give a baseline for professional conduct as it pertains to quality.  The council would also provide a coherent national focal point for market-led ML activity, presenting a visible and open front door to engage end-users and international inward investment.  

# Machine Learning and Software 

{:.BodyText .Justified}
To all practical intents and purpose Machine learning is a statistically focussed subset of software development. Thus, software faces many of the same issues as machine learning and many more that ML have yet to tackle in detail; primarily in privacy and security.  

{:.BodyText .Justified}
GDPR was a sensible regulatory response to a growing concern within society over how user’s data is handled by large software corporations. However, it is by no means an all-encompassing solution to the problem of the ethics of user’s data ownership and consent. A true solution will only be achieved through a continuous self-review and regulation mechanism. The same is also true with the response to cyber-security, which is already a deeply studied area within the community; however, the advice of cyber-security experts is often ignored leading to significant risks within infrastructure [21]. A professional body would apply both pressures to the developer and support the developer in pressuring the corporations to adequately implementing cyber-security, in the same manner that civil engineers maintain safety. 

{:.BodyText .Justified}
Another pending issue within the software community is quality. To some degree this quality crisis has been masked by Moore’s law. For example, word processors since 1995 have only gained very few key features but have become slower in user response and 1000s of times larger, during 30 years of hardware performance doubling every 1.5 years; this is commonly referred to as Wirth’s law. Moreover, almost all users have become accepting to the point of blindness to the inevitability of software bugs and failure, something that would not be accepted in any other profession.  As a related consideration, software development would benefit from a training scheme that requires in-work training, like many other professions. “Software carpentry” is a growing movement within the community to lead inclusive community teaching data and coding skills, leading to a concept of a software apprenticeship, with programming being treated as a craft to be mastered. 

 

Figure 3: Venn diagram for the field research of Machine Learning and related fields. 

{:.BodyText .Justified}
The natural alignment between Software and Autonomous system would make their combined profession a logical union.  

# Related Work 

{:.BodyText .Justified}
The following is a brief exploration of the related work of establishing self-regulation within Machine learning and the software community. One such is the adoption of “Algorithmic assessment studies” by governments such as Canada [22]. “Algorithmic assessment studies” aim to minimise the potential impacts on society of potentially “racist” or un-inclusive algorithms that lead to algorithmic bias [23]. However, the fixed assessment does not give an adequate mechanism as it is not flexible enough to consider larger or outlier cases or suggest reasonable remediation actions. Algorithmic impact assessments defined by a professional body augmented with ethics committees for necessary cases would provide an excellent mechanism for ethical review. 

{:.BodyText .Justified}
It is worth noting that it is unlikely that there will be a push towards greater ethics from the existing community leadership. Currently, leadership undoubtedly resides at corporations like Google, housing the vast majority of the research financing and driving the labour market. However, recent history has demonstrated that corporations are not equipped to perform the task of self-regulation, much less regulate the wider community. For illustration; in 2019 Google established an independent group, the Advanced Technology External Advisory Council (ATEAC) to look at the ethics around AI, machine learning and facial recognition [24]. This committee was disbanded within 2 weeks due to ethical concerns. Whilst unsuccessful in its stated goals this effort was successful in demonstrating the need for such a third party and engaging the relevant experts such as Prof Alessandro Acquisti who resigned, tweeting: "While I'm devoted to research grappling with key ethical issues of fairness, rights and inclusion in AI, I don't believe this is the right forum for me to engage in this important work." [25]. 

{:.BodyText .Justified}
As a different example of the growing interest and will to implement ethical regulations, take the enigmatic Institute for Ethical AI & Machine Learning, which advocates for responsible machine learning. The institute proposes 8 principles of responsible ML development to provide a practical framework to support technologists when designing, developing or maintaining systems that learn from data, and even proposes a 4-year timeline for regulation, although doesn’t discuss the details of how this regulation would come to be. However, more importantly, is the list of community leaders have already pledged themselves to the Institute’s principles voluntarily, demonstrating a desire for ethics within ML  [26].  

{:.BodyText .Justified}
Within the UK Robotics and Autonomous system community, there have been significant efforts to establish some ethical standards, with several technical parliamentary inquiries published [20], and the British Standard 8611:2016 “Robots and robotic devices. Guide to the ethical design and application of robots and robotic systems”, which is possibly the world’s first standard on robot ethics. This Standard forms the basis of how self-regulation would be applied, presenting concepts such as Ethical risk assessments, but still needs a mechanism to ensure regulation. 

# Conclusion 

{:.BodyText .Justified}
As argued for the benefit of the community and society Software Engineering and Machine Learning must self-regulate its research and application through the implementation of self-governing professional bodies. The profession would need to encourage membership through the benefits, and external pressures possibly applied through the condition of employment.  

{:.BodyText .Justified}
A profession would need to be formed with wide agreement from academia, government, industry, and the public. For this, a broad working group would need to be formed, and action taken rapidly towards the formation of a formal profession with a governing body. It is likely that within this, no true consensus will be found for the nature of that profession within a sensible timeline. However, as long at least one professional body is formed and another formed as an alternative, it doesn’t matter; multiple governing bodies may increase the overall ethics of the community providing a review mechanism for the profession. If we do not act quickly the consequences will be damaging society and the communities.  

​References 

 

* [1]  D. K. Citron and R. . Chesney, “Deepfakes and the New Disinformation War,” Foreign Affairs, vol. , no. , p. , 2018.  
* [2]  J. . Roettgers, “Porn Producers Offer to Help Hollywood Take Down Deepfake Videos,” , . [Online]. Available: https://variety.com/2018/digital/news/deepfakes-porn-adult-industry-1202705749/. [Accessed 4 12 2019]. 
* [3]  D. O'Sullivan, “Congress to investigate deepfakes as doctored Pelosi video causes stir,” CNN, June 2019. [Online]. Available: https://edition.cnn.com/2019/06/04/politics/house-intelligence-committee-deepfakes-threats-hearing/index.html. 
* [4]  Y. Jia, Y. Zhang and R. Weiss, “Transfer learning from speaker verification to multispeaker text-to-speech synthesis,” in Advances in neural information processing systems, 2018.  
* [5]  N. Statt, “Thieves are now using AI deepfakes to trick companies into sending them money,” The Verge, 5 September 2019. [Online]. Available: https://www.theverge.com/2019/9/5/20851248/deepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money. 
* [6]  “History of Research Ethics,” University of Missouri-Kansas City, [Online]. Available: http://ors.umkc.edu/research-compliance/institutional-review-board-(irb)/history-of-research-ethics. 
* [7]  R. Hewlett, O. Anderson and A. Snell, “The new world, 1939/1946,” Physics Today, vol. 15, p. 62, 1962.  
* [8]  K. e. Hentschel, Physics and national socialism: An anthology of primary sources, Springer Science & Business Media, 2011.  
* [9]  R. Hewlett, O. Anderson and A. Snell, “The new world, 1939/1946,” Physics Today, vol. 15, p. 62, 1962.  
* [10]  NHS Executive, “Report of a review of the research framework in North Staffordshire Hospital NHS Trust,” NHS, 2000. 
* [11]  C. Vanu Som, “Clinical governance: a fresh look at its definition,” Clinical Governance: An International Journal, vol. 9, no. 2, pp. 87-90, 2004.  
* [12]  D. B. Resnik, “Research Ethics Timeline,” National Institute of Environmental Health Sciences. , 2018. [Online]. Available: https://www.niehs.nih.gov/research/resources/bioethics/timeline/index.cfm.. 
* [13]  E. McDonach, R. Barbour and B. Williams, “Reflections on applying for NHS ethical approval and governance in a climate of rapid change: prioritising process over principles,” International Journal of Social Research Methodology, vol. 12, no. 3, pp. 227-241, 2009.  
* [14]  B. J. Yeazel, “ Bomb-Making Manauls on the Internet: Maneuvering a Solution through First Amendment Jurisprudence,” Notre Dame JL Ethics \& Pub. Pol'y, vol. 16, p. 279, 2002.  
* [15]  R. Horton, “The lessons of MMR,” The Lancet, vol. 363, no. 9411, p. 747–9, 2004.  
* [16]  R. Peng, “The reproducibility crisis in science: A statistical counterattack,” Significance, vol. 12, no. 3, pp. 30-32, 2015.  
* [17]  M. Hutson, Artificial intelligence faces reproducibility crisis, American Association for the Advancement of Science, 2018.  
* [18]  S. Begley, “Claim of CRISPR’d baby girls stuns genome editing summit,” Stat news, 26 November 2018. [Online]. Available: https://www.statnews.com/2018/11/26/claim-of-crispred-baby-girls-stuns-genome-editing-summit/. 
* [19]  Robotics and Autonomous Systems Special Interest Group, “RAS 2020: Robotics and autonomous systems,” UK, 2014. 
* [20]  Select Committee on Artificial Intelligence, “AI in the UK:ready, willing and able?,” House of Lords, UK, 2018. 
* [21]  T. . Vagoun and G. O. Strawn, “Implementing the Federal Cybersecurity RaD Strategy,” IEEE Computer, vol. 48, no. 4, pp. 45-55, 2015.  
* [22]  F. . McKelvey and M. . Macdonald, “Artificial Intelligence Policy Innovations at the Canadian Federal Government,” Canadian journal of communication, vol. 44, no. 2, p. , 2019.  
* [23]  A. . Koene, “Algorithmic Bias: Addressing Growing Concerns [Leading Edge],” IEEE Technology and Society Magazine, vol. 36, no. 2, pp. 31-32, 2017.  
* [24]  “An external advisory council to help advance the responsible development of AI,” , . [Online]. Available: https://www.blog.google/technology/ai/external-advisory-council-help-advance-responsible-development-ai/. [Accessed 11 12 2019]. 
* [25]  J. Wakefield, “Google's ethics board shut down,” BBC, 5 April 2019. [Online]. Available: https://www.bbc.co.uk/news/technology-47825833. 
* [26]  Ethical Institue, “Ethical AI Network,” 2019. [Online]. Available: https://ethical.institute/network.html. 